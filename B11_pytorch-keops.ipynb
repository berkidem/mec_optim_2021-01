{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "m+e+c GPUs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b188OSq0Obf1"
      },
      "source": [
        "# Google Colab, PyTorch, KeOps\n",
        "\n",
        "by Flavien LÃ©ger.\n",
        "\n",
        "Math+econ+code, Feb 5 2021\n",
        "\n",
        "References and resources:\n",
        "* PyTorch: https://pytorch.org/docs/stable/index.html\n",
        "* KeOps: https://www.kernel-operations.io/keops/index.html\n",
        "* Jean Feydy's PhD thesis: https://www.jeanfeydy.com/geometric_data_analysis.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrPT6B6sN75p"
      },
      "source": [
        "# 0. Imports (run once)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xeCWfKrN8pc"
      },
      "source": [
        "from time import time\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install pykeops[full] > install.log\n",
        "from pykeops.torch import LazyTensor\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCgnE-qbYi1I"
      },
      "source": [
        "# 1. PyTorch and tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDhRFdV8PkyZ"
      },
      "source": [
        "## a) Basic operations\n",
        "\n",
        "PyTorch uses **tensors**, i.e. a multidimensional array (a generalization of a matrix).\n",
        "\n",
        "One-dimensional tensor: $x_i$ for $i=1,\\dots,n$.\n",
        "\n",
        "Two-dimensional tensor: $x_{ij}$ for $i=1,\\dots,n, j=1,\\dots,m$.\n",
        "\n",
        "Three-dimensional tensor: $x_{ijk}$ for $i=1,\\dots,n$, $j=1,\\dots,m$, $k=1,\\dots,\\ell$.\n",
        "\n",
        "etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yKtwOurTfRW"
      },
      "source": [
        "# Some basic commands\n",
        "\n",
        "x = torch.zeros(4, 5)   # or: x = torch.zeros( (4, 5) )\n",
        "x = torch.ones(3, 2)\n",
        "x = torch.linspace(0, 1, 10)\n",
        "x = torch.rand(3, 1, 5)\n",
        "x = torch.randn(2, 2, 3)\n",
        "print(f'x = {x}')\n",
        "print(f'x size: {x.size()}\\n')    # or x.shape like in NumPy\n",
        "\n",
        "# Construct a tensor from data\n",
        "y = torch.Tensor([-4,20,1])\n",
        "print(f'y = {y}')\n",
        "print(f'y size: {y.size()}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76iUQqm5VdRI"
      },
      "source": [
        "## b) Reduction operations\n",
        "Given a 2d tensor $A_{ij}$ we might want to\n",
        " - take a sum $x_j = \\sum_i A_{ij}$\n",
        " - take a maximum $y_i = \\max_jA_{ij}$ \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN958GdFT3ur"
      },
      "source": [
        "torch.manual_seed(20210204)\n",
        "\n",
        "# Sum\n",
        "A = torch.rand(7, 2)           # (7, 2) tensor\n",
        "x = A.sum(dim=0)                # one-dimensional tensor of size 2 \n",
        "\n",
        "print(f'A = {A}\\n')\n",
        "print(f'x = {x}\\n')\n",
        "\n",
        "# Min or max\n",
        "y, T = A.max(dim=1)\n",
        "print(f'y = {y}')\n",
        "print(f'T = {T}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMjF7zpkUiDr"
      },
      "source": [
        "## c) Broadcasting\n",
        "\n",
        "Imagine you have two 1d tensors (i.e. vectors) $x_i$ and $y_j$ ($i=1,\\dots,n$, $j=1,\\dots,m$), and you want to compute the 2d tensors\n",
        "$$\n",
        "S_{ij}=x_i+y_j\n",
        "$$\n",
        "or\n",
        "$$\n",
        "P_{ij} = x_i y_j.\n",
        "$$\n",
        "\n",
        "We can add a dummy dimension to $x$ and $y$ and then *broadcast* the sum or multiplication.\n",
        "\n",
        "See: http://scipy.github.io/old-wiki/pages/EricsBroadcastingDoc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU7zp0wTYs7g"
      },
      "source": [
        "x = torch.arange(0, 3)  # 1d tensor of length 3\n",
        "y = torch.arange(0, 5)  # 1d tensor of length 5\n",
        "\n",
        "x = x[:, None]  # x is now a 2d tensor of shape (3,1)\n",
        "y = y[None, :]  # y is now a 2d tensor of shape (1,5)\n",
        "S = x + y\n",
        "\n",
        "print(f'x = {x}\\n')\n",
        "print(f'y = {y}\\n')\n",
        "print(f'S = {S}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlUXc2MlYZDA"
      },
      "source": [
        "## d) Example 1: compute a $\\Phi$-transform\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbiCtbbBQOqR"
      },
      "source": [
        "def plot_pquv(x, y, u, v, max_points=1000):\n",
        "  N = x.size(0)\n",
        "  M = y.size(0)\n",
        "  if x.device.type == 'cuda':\n",
        "    x = x.cpu()\n",
        "  if y.device.type == 'cuda':\n",
        "    y = y.cpu()\n",
        "  if u.device.type == 'cuda':\n",
        "    u = u.cpu()\n",
        "  if v.device.type == 'cuda':\n",
        "    v = v.cpu()\n",
        "\n",
        "\n",
        "\n",
        "  idx1 = random.sample(range(N),max_points) if N > max_points else range(N)\n",
        "  idx2 = random.sample(range(M),max_points) if M > max_points else range(M)\n",
        "\n",
        "  plt.rcParams['figure.figsize'] = [12, 8]\n",
        "  fig, ax = plt.subplots(1, 2, sharex=True, sharey=True)\n",
        "  plt.setp(ax.flat, aspect=1.0, adjustable='box')\n",
        "  ax[0].scatter(x[idx1,0], x[idx1,1], c=u[idx1])\n",
        "  ax[0].set_title('p and u')\n",
        "  ax[1].scatter(y[idx2,0], y[idx2,1], c=v[idx2])\n",
        "  ax[1].set_title('q and v')\n",
        "\n",
        "\n",
        "\n",
        "def plot_pqT(x, y, T, max_points=100):\n",
        "  N = x.size(0)\n",
        "  M = y.size(0)\n",
        "\n",
        "  idx1 = random.sample(range(N),max_points) if N > max_points else range(N)\n",
        "  idx2 = T[idx1]\n",
        "\n",
        "  plt.rcParams['figure.figsize'] = [24, 8]\n",
        "  fig, ax = plt.subplots(1, 4, sharex=True, sharey=True)\n",
        "  plt.setp(ax.flat, aspect=1.0, adjustable='box')\n",
        "\n",
        "  ax[0].scatter(x[idx1,0], x[idx1,1], c='C0')\n",
        "  ax[0].set_title('p')\n",
        "\n",
        "  ax[1].scatter(y[idx2,0], y[idx2,1], c='C1')\n",
        "  ax[1].set_title('q')\n",
        "\n",
        "  ax[2].quiver(x[idx1,0], x[idx1,1], y[idx2, 0]-x[idx1,0], y[idx2,1]-x[idx1,1], angles='xy', scale_units='xy', scale=1, alpha=0.2);\n",
        "  ax[2].scatter(x[idx1,0], x[idx1,1], alpha=0.2)\n",
        "  ax[2].scatter(y[idx2,0], y[idx2,1], c=v[idx2])\n",
        "  ax[2].set_title('Matching T with prices $v_j$')\n",
        "\n",
        "  ax[3].scatter(x[idx1,0], x[idx1,1], c=u[idx1])\n",
        "  ax[3].set_title('Indirect utility $u_i$')\n",
        "\n",
        "\n",
        "\n",
        "def init_twonormals(N, M, seed=20210204):\n",
        "  x = torch.randn((N,2))    # (N,2)\n",
        "  y = torch.randn((M,2))    # (M,2)\n",
        "  y /= 3\n",
        "  return x, y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbceetEPUgtD"
      },
      "source": [
        "\n",
        "Assume $(x_i)\\in \\mathbb{R}^{n\\times 2}$ and $(y_j)\\in\\mathbb{R}^{m\\times 2}$ are points 2d. Compute the surplus matrix\n",
        "$$\n",
        "\\Phi_{ij} = - \\lVert x_i-y_j\\rVert^2. \n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc4p_obFPkXJ"
      },
      "source": [
        "N, M = 10, 3\n",
        "# N, M = 1000, 3000\n",
        "\n",
        "x, y = init_twonormals(N, M)\n",
        "\n",
        "\n",
        "x_i = x[:, None, :]   # (N, 1, 2) torch tensor\n",
        "y_j = y[None, :, :]   # (1, M, 2) torch tensor\n",
        "tic = time()\n",
        "### BEGINNING OF YOUR CODE\n",
        "\n",
        "Phi_ij = (-(x_i - y_j) ** 2).sum(dim=-1)   # (N, M) tensor of squared distances |x_i-y_j|^2\n",
        "\n",
        "### END OF YOUR CODE\n",
        "toc = time()\n",
        "print(f'Surplus matrix CPU time: {toc-tic:.5f}s')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKWdyEg8W85s"
      },
      "source": [
        "$$\n",
        "\\DeclareMathOperator*{\\argmin}{argmin}\n",
        "\\DeclareMathOperator*{\\argmax}{argmax}\n",
        "$$\n",
        "Let $v_j$ be the price at $y_j$. Compute the indirect utility\n",
        "$$\n",
        "u_i := \\max_j \\Phi_{ij}-v_j.\n",
        "$$\n",
        "Also retrieve the associated map\n",
        "$$\n",
        "T_i := \\argmax_j \\Phi_{ij}-v_j.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LbWAJEEUua-"
      },
      "source": [
        "\n",
        "v = 3*y[:,0]\n",
        "v_j = v[None, :]      # (1, M) \n",
        "\n",
        "\n",
        "\n",
        "tic = time()\n",
        "\n",
        "# Broadcasting and max reduction\n",
        "### BEGINNING OF YOUR CODE\n",
        "\n",
        "u, T = (Phi_ij - v_j).max(dim=1)   # (M, )\n",
        "\n",
        "### END OF YOUR CODE\n",
        "toc = time()\n",
        "print(f'Î¦-transform CPU time: {toc-tic:.5f}s\\n')\n",
        "\n",
        "plot_pqT(x, y, T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofrQSb6rCiDN"
      },
      "source": [
        "## e) Example 2: compute a log-sum-exp\n",
        "\n",
        "When doing regularized OT, the $\\Phi$-transform is replaced by **log-sum-exp** operations\n",
        "\n",
        "$$\n",
        "u_i = \\sigma\\ln\\Big(\\sum_j\\exp\\Big(\\frac{\\Phi_{ij}-v_j}{\\sigma}\\Big)\\Big) - \\sigma\\ln p_i\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMjc0Ok9YzGj"
      },
      "source": [
        "# Same as before ---------------------------------------------------------------\n",
        "N, M = 10, 3\n",
        "# N, M = 10_000, 10_000\n",
        "\n",
        "x, y = init_twonormals(N, M)\n",
        "x_i = x[:, None, :]   # (N, 1, 2) torch tensor\n",
        "y_j = y[None, :, :]   # (1, M, 2) torch tensor\n",
        "tic = time()\n",
        "\n",
        "Phi_ij = (-(x_i - y_j) ** 2).sum(dim=-1)   # (N, M) tensor of squared distances |x_i-y_j|^2\n",
        "toc = time()\n",
        "print(f'Surplus matrix CPU time: {toc-tic:.5f}s')\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "v = 3*y[:,0]\n",
        "v_j = v[None, :]      # (1, M) \n",
        "\n",
        "sigma = 0.1\n",
        "# sigma = 0.001\n",
        "\n",
        "tic = time()\n",
        "# Numerically stabilized\n",
        "### BEGINNING OF YOUR CODE\n",
        "\n",
        "u = sigma *((Phi_ij - v_j)/sigma).logsumexp(dim=1) - sigma*np.log(1/N)   # (M, )\n",
        "\n",
        "### END OF YOUR CODE\n",
        "toc = time()\n",
        "print(f'Î¦-transform CPU time: {toc-tic:.5f}s\\n')\n",
        "\n",
        "plot_pquv(x,y,u,v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOCupuDybpWL"
      },
      "source": [
        "#### Comparing max and softmax\n",
        "\n",
        "For a price vector $v$ denote\n",
        "$$\n",
        "u^{(0)}_i := \\max_j \\Phi_{ij}-v_j.\n",
        "$$\n",
        "and for $\\sigma>0$\n",
        "$$\n",
        "u^{(\\sigma)}_i = \\sigma\\ln\\Big(\\sum_j\\exp\\Big(\\frac{\\Phi_{ij}-v_j}{\\sigma}\\Big)\\Big) - \\sigma\\ln p_i\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEj5fN2NGWv-"
      },
      "source": [
        "\n",
        "# Compare max and softmax\n",
        "\n",
        "v = 3*y[:,0]\n",
        "v_j = v[None, :]      # (1, M) \n",
        "\n",
        "u_0, _ = (Phi_ij - v_j).max(dim=1)   # (M, )\n",
        "\n",
        "sigma = 0.001\n",
        "u_sigma = sigma *((Phi_ij - v_j)/sigma).logsumexp(dim=1) - sigma*np.log(1/N)   # (M, )\n",
        "\n",
        "plt.plot(u_sigma-u_0)\n",
        "plt.title('Difference $u^{(\\sigma)}-u^{(0)}$');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTFfl7qYS7N3"
      },
      "source": [
        "# 2. PyTorch and GPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbcCe0NTc1SB"
      },
      "source": [
        "\n",
        "N, M = 1_000, 1_000\n",
        "# N, M = 100_000, 10_000  # comment CPU code\n",
        "\n",
        "x, y = init_twonormals(N, M)\n",
        "v = 3*y[:,0]\n",
        "\n",
        "# CPU code ---------------------------------------------------------------------\n",
        "x_i = x[:, None, :]   # (N, 1, 2) torch tensor\n",
        "y_j = y[None, :, :]   # (1, M, 2) torch tensor\n",
        "v_j = v[None, :]     # (1, M) \n",
        "\n",
        "tic = time()\n",
        "Phi_ij = (-(x_i - y_j) ** 2).sum(dim=-1)   # (N, M) tensor of squared distances |x_i-y_j|^2\n",
        "u, T = (Phi_ij - v_j).max(dim=1)   # (M, )\n",
        "toc = time()\n",
        "print(f'CPU time: {toc-tic:.5f}s')\n",
        "\n",
        "\n",
        "# GPU code ---------------------------------------------------------------------\n",
        "x_i = x[:, None, :].cuda()   # (N, 1, 2) torch tensor\n",
        "y_j = y[None, :, :].cuda()   # (1, M, 2) torch tensor\n",
        "v_j = v[None, :].cuda()      # (1, M) \n",
        "\n",
        "tic = time()\n",
        "Phi_ij = (-(x_i - y_j) ** 2).sum(dim=-1)   # (N, M) tensor of squared distances |x_i-y_j|^2\n",
        "u, T = (Phi_ij - v_j).max(dim=1)   # (M, )\n",
        "toc = time()\n",
        "print(f'GPU time: {toc-tic:.5f}s')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGdiGQ3KlTar"
      },
      "source": [
        "## Example: IPFP\n",
        "\n",
        "\n",
        "Recall the regularized OT problem\n",
        "$$\n",
        "\\min_{u,v} \\sum_j v_jq_j+\\sum_iu_ip_i+\\sigma\\ln\\Big(\\sum_{ij}\\exp\\Big(\\frac{\\Phi_{ij}-u_i-v_j}{\\sigma}\\Big)\\Big)=:F(u,v)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b357yFMolShE"
      },
      "source": [
        "def compute_ipfp(Phi_ij, sigma, numIters):\n",
        "  N, M = Phi_ij.size()\n",
        "  v = torch.zeros(M).cuda()\n",
        "  u = torch.zeros(N).cuda()\n",
        "  dual_values = np.empty(numIters+1)\n",
        "  KL_errors = np.empty(numIters+1)\n",
        "\n",
        "  printBlock = numIters//20 if numIters>20 else 1\n",
        "\n",
        "  for k in range(numIters+1):\n",
        "    \n",
        "    v_j = v[None, :]\n",
        "    u = sigma * ( (Phi_ij - v_j) / sigma ).logsumexp(axis=1) - sigma*np.log(1/N)\n",
        "    \n",
        "    u_i = u[:, None]\n",
        "    new_v = sigma * ( (Phi_ij -u_i) / sigma ).logsumexp(axis=0) - sigma*np.log(1/M)\n",
        "    \n",
        "    # \n",
        "    dual_value = (v.sum()/M + u.sum()/N)\n",
        "    kl_err = 1/sigma * (v-new_v).sum()/M\n",
        "    #\n",
        "\n",
        "    v = new_v\n",
        "\n",
        "    dual_values[k] = dual_value\n",
        "    KL_errors[k] = kl_err\n",
        "\n",
        "    if k % printBlock == 0:      \n",
        "      print(f'Iter {k:4d}/{numIters},   F = {dual_value:6f},   KL err = {kl_err:6f}')\n",
        "\n",
        "  return v, u, dual_values, KL_errors\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S7ozOevnvTO"
      },
      "source": [
        "N, M = 1_000, 1_000\n",
        "# N, M = 100_000, 10_000\n",
        "\n",
        "x, y = init_twonormals(N, M)\n",
        "x_i = x[:, None, :].cuda()   # (N, 1, 2) torch tensor\n",
        "y_j = y[None, :, :].cuda()   # (1, M, 2) torch tensor\n",
        "Phi_ij = (-(x_i - y_j) ** 2).sum(dim=-1)   # (N, M) tensor of squared distances |x_i-y_j|^2\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "sigma = 1e-1\n",
        "\n",
        "numIters = int(3/sigma)\n",
        "\n",
        "tic = time()\n",
        "v, u, dual_values, KL_errors = compute_ipfp(Phi_ij, sigma, numIters)\n",
        "toc = time()\n",
        "print(f'\\nIPFP GPU time: {toc-tic:.5f}s')\n",
        "plt.semilogy(KL_errors)\n",
        "plt.xlabel('iteration count')\n",
        "plt.title('Errors KL(q|$\\pi_2$)');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dw6g6W0BxOi"
      },
      "source": [
        "# 3. KeOps\n",
        "\n",
        "For a large scale computation\n",
        "\n",
        "$$\n",
        "u_i := \\max_j \\Phi_{ij}-v_j.\n",
        "$$\n",
        "\n",
        "the GPU runs out of memory when $NM \\gtrsim 10^8$ since it cannot store $\\Phi_{ij}$. But recall that \n",
        "$$\\Phi_{ij}=\\|x_i-y_i\\|^2,$$\n",
        "so we shouldn't *have to* store it.\n",
        "\n",
        "KeOps uses *lazy tensors* that can keep $\\Phi$ as a *formula*. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgzHsBw4Byfg"
      },
      "source": [
        "\n",
        "# PyTorch + KeOps\n",
        "\n",
        "N, M = 100_000, 10_000\n",
        "# N, M = 1_000_000, 1_000_000\n",
        "\n",
        "x, y = init_twonormals(N, M)\n",
        "v = 3*y[:,0]\n",
        "\n",
        "x_i = LazyTensor(x[:, None, :].cuda())   # (N, 1, 2) torch tensor\n",
        "y_j = LazyTensor(y[None, :, :].cuda())   # (1, M, 2) torch tensor\n",
        "\n",
        "# # # # # # # # # \n",
        "Phi_ij = (-(x_i - y_j) ** 2).sum(dim=-1)   # (N, M) LAZY tensor of squared distances |x_i-y_j|^2\n",
        "# # # # # # # # # \n",
        "\n",
        "\n",
        "v = -y[:,0]\n",
        "v_j = LazyTensor(v[:, None].cuda(), axis=1)      # (1, M) \n",
        "\n",
        "tic = time()\n",
        "\n",
        "# Broadcasting and max reduction\n",
        "u, T = (Phi_ij - v_j).max_argmax(dim=1)   # (M, )\n",
        "\n",
        "toc = time()\n",
        "print(f'N = {N}, M = {M}')\n",
        "print(f'Î¦-transform GPU time: {toc-tic:.5f}s')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBO7hed7xlkV"
      },
      "source": [
        "## Example: large-scale IPFP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cK-Fhd_kxkbG"
      },
      "source": [
        "def compute_lazy_ipfp(Phi_ij, sigma, numIters):\n",
        "  N, M = Phi_ij.ni, Phi_ij.nj\n",
        "  v = torch.zeros(M, 1).cuda()  \n",
        "  u = torch.zeros(N, 1).cuda()\n",
        "  dual_values = np.empty(numIters+1)\n",
        "  KL_errors = np.empty(numIters+1)\n",
        "\n",
        "\n",
        "  printBlock = numIters//20 if numIters>20 else 1\n",
        "\n",
        "\n",
        "  for k in range(numIters+1):\n",
        "    \n",
        "    v_j = LazyTensor(v, axis=1)   # shape = (1, M)\n",
        "    u = sigma * ( (Phi_ij - v_j) / sigma ).logsumexp(axis=1) - sigma*np.log(1/N)\n",
        "    \n",
        "    u_i = LazyTensor(u, axis=0)\n",
        "    new_v = sigma * ( (Phi_ij -u_i) / sigma ).logsumexp(axis=0) - sigma*np.log(1/M)\n",
        "    \n",
        "    # \n",
        "    dual_value = (v.sum()/M + u.sum()/N)\n",
        "    kl_err = 1/sigma * (v-new_v).sum()/M\n",
        "    #\n",
        "\n",
        "    v = new_v\n",
        "\n",
        "    dual_values[k] = dual_value\n",
        "    KL_errors[k] = kl_err\n",
        "\n",
        "    if k % printBlock == 0:      \n",
        "      print(f'Iter {k:4d}/{numIters},   F = {dual_value:6f},   KL err = {kl_err:6f}')\n",
        "\n",
        "\n",
        "  return v, u, dual_values, KL_errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3wvQnRYscTI"
      },
      "source": [
        "# N, M = 100_000, 10_000\n",
        "N, M = 1_000_000, 100_000\n",
        "\n",
        "x, y = init_twonormals(N, M)\n",
        "x_i = LazyTensor(x[:, None, :].cuda())   # (N, 1, 2) torch tensor\n",
        "y_j = LazyTensor(y[None, :, :].cuda())   # (1, M, 2) torch tensor\n",
        "Phi_ij = (-(x_i - y_j) ** 2).sum(dim=-1)   # (N, M) tensor of squared distances |x_i-y_j|^2\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "sigma = 1e-1\n",
        "\n",
        "numIters = int(3/sigma)\n",
        "\n",
        "print(f'N = {N}, M = {M}\\n')\n",
        "tic = time()\n",
        "v, u, dual_values, KL_errors = compute_lazy_ipfp(Phi_ij, sigma, numIters)\n",
        "toc = time()\n",
        "\n",
        "print(f'\\nIPFP GPU time: {toc-tic:.5f}s')\n",
        "plt.semilogy(KL_errors)\n",
        "plt.xlabel('iteration count')\n",
        "plt.title('Errors KL(q|$\\pi_2$)');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GS0mUMRy7M_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}